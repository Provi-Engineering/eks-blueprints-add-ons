controller:
  replicas: 1 # Additional replicas will cause sharding of managed clusters across number of replicas.
  metrics:
    enabled: true
    service:
      annotations:
        prometheus.io/scrape: true
  env:
    - name: ARGOCD_K8S_CLIENT_QPS #required for Crossplane too many CRDs https://github.com/argoproj/argo-cd/pull/448
      value: '300'

repoServer:
  autoscaling:
    enabled: true
    minReplicas: 1
  resources: # Adjust based on your specific use case (required for HPA)
    requests:
      cpu: '100m'
      memory: '256Mi'
    limits:
      cpu: '200m'
      memory: '512Mi'
  metrics:
    enabled: true
    service:
      annotations:
        prometheus.io/scrape: true

applicationSet:
  replicaCount: 1 # The controller doesn't scale horizontally, is active-standby replicas
  metrics:
    enabled: true
    service:
      annotations:
        prometheus.io/scrape: true

server:
  autoscaling:
    enabled: true
    minReplicas: 1
  resources: # Adjust based on your specific use case (required for HPA)
    requests:
      cpu: '100m'
      memory: '256Mi'
    limits:
      cpu: '200m'
      memory: '512Mi'
  metrics:
    enabled: true
    service:
      annotations:
        prometheus.io/scrape: true
  service:
    type: ClusterIP
    annotations:
      service.beta.kubernetes.io/aws-load-balancer-scheme: internal
#  ingress:
#    enabled: true
#    ingressClassName: alb
#    hostname: argocd.${domain}
#    annotations:
#      alb.ingress.kubernetes.io/backend-protocol: HTTPS
#      alb.ingress.kubernetes.io/certificate-arn: ${cert_arn}
#      alb.ingress.kubernetes.io/healthcheck-path: /healthz
#      alb.ingress.kubernetes.io/healthcheck-protocol: HTTPS
#      alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS":443}]'
#      alb.ingress.kubernetes.io/scheme: internal
#      alb.ingress.kubernetes.io/ssl-redirect: "443"
#      alb.ingress.kubernetes.io/tags: Name=argocd-alb
#      alb.ingress.kubernetes.io/target-type: ip
#      external-dns.alpha.kubernetes.io/hostname: argocd.${domain}
#      nginx.ingress.kubernetes.io/proxy-body-size: "0"
#      provi.repository: https://github.com/Provi-Engineering/provi-eks-blueprints
#      provi.slack: talk-devops
#      external-dns.alpha.kubernetes.io/ttl: "10"
#      external-dns.alpha.kubernetes.io/aws-weight: "${aws_weight}"
#      external-dns.alpha.kubernetes.io/set-identifier: ${cluster_name}

configs:
  repositories:
    # Required when using helm repository with oci formal like karpenter and aws-gateway-api-controller
    aws-public-ecr:
      name: aws-public-ecr
      type: helm
      url: public.ecr.aws
      enableOCI: 'true'
#    provi-helm-charts:
#      url: https://provi-helm-charts.pvfog.org
#      name: provi-helm-charts
#      type: helm
#    provi-engineering:
#      url: git@github.com:Provi-Engineering

  rbac:
    policy.default: "role:dev"
    policy.csv: |
      p, role:dev, applications, get, default/*, allow
      p, role:dev, applications, create, default/*, allow
      p, role:dev, applications, update, default/*, allow
      p, role:dev, applications, delete, default/*, allow
      p, role:dev, applications, sync, default/*, allow
      p, role:dev, applications, override, default/*, allow
      p, role:dev, applications, action/*, default/*, allow
      p, role:dev, exec, create, default/*, allow
      p, role:dev, certificates, get, default/*, allow
      p, role:dev, clusters, get, default/*, allow
      p, role:dev, repositories, get, default/*, allow
      p, role:dev, projects, get, default/*, allow
      p, role:dev, accounts, get, default/*, allow
      p, role:dev, gpgkeys, get, default/*, allow
      p, role:dev, logs, get, default/*, allow

      g, Provi-Engineering:DevOps, role:admin

  cm:
    application.resourceTrackingMethod: 'annotation' #use annotation for tracking required for Crossplane
    resource.exclusions: |
      - kinds:
        - ProviderConfigUsage
        apiGroups:
        - "*"
    resource.customizations: |
      "awsblueprints.io/*":
        health.lua: |
          health_status = {
            status = "Progressing",
            message = "Provisioning ..."
          }

          if obj.status == nil or obj.status.conditions == nil then
            return health_status
          end

          for i, condition in ipairs(obj.status.conditions) do
            if condition.type == "Ready" then
              if condition.status == "True" then
                health_status.status = "Healthy"
                health_status.message = "Resource is up-to-date."
                return health_status
              end
            end

            if condition.type == "LastAsyncOperation" then
              if condition.status == "False" then
                health_status.status = "Degraded"
                health_status.message = condition.message
                return health_status
              end
            end

            if condition.type == "Synced" then
              if condition.status == "False" then
                health_status.status = "Degraded"
                health_status.message = condition.message
                return health_status
              end
            end
          end

          return health_status

      "*.aws.upbound.io/*":
        health.lua: |
          health_status = {
            status = "Progressing",
            message = "Provisioning ..."
          }

          if obj.status == nil or obj.status.conditions == nil then
            return health_status
          end

          for i, condition in ipairs(obj.status.conditions) do
            if condition.type == "Ready" then
              if condition.status == "True" then
                health_status.status = "Healthy"
                health_status.message = "Resource is up-to-date."
                return health_status
              end
            end

            if condition.type == "LastAsyncOperation" then
              if condition.status == "False" then
                health_status.status = "Degraded"
                health_status.message = condition.message
                return health_status
              end
            end

            if condition.type == "Synced" then
              if condition.status == "False" then
                health_status.status = "Degraded"
                health_status.message = condition.message
                return health_status
              end
            end
          end

          return health_status

      "*.aws.crossplane.io/*":
        health.lua: |
          health_status = {
            status = "Progressing",
            message = "Provisioning ..."
          }

          if obj.status == nil or obj.status.conditions == nil then
            return health_status
          end

          for i, condition in ipairs(obj.status.conditions) do
            if condition.type == "Ready" then
              if condition.status == "True" then
                health_status.status = "Healthy"
                health_status.message = "Resource is up-to-date."
                return health_status
              end
            end

            if condition.type == "LastAsyncOperation" then
              if condition.status == "False" then
                health_status.status = "Degraded"
                health_status.message = condition.message
                return health_status
              end
            end

            if condition.type == "Synced" then
              if condition.status == "False" then
                health_status.status = "Degraded"
                health_status.message = condition.message
                return health_status
              end
            end
          end

          return health_status

# -- Array of extra K8s manifests to deploy
## Note: Supports use of custom Helm templates
##       It gets handle in this form inside the argo-cd chart
# {{ range .Values.extraObjects }}
# ---
# {{ if typeIs "string" . }}
#     {{- tpl . $ }}
# {{- else }}
#     {{- tpl (toYaml .) $ }}
# {{- end }}
# {{ end }}
extraObjects:
  - |
    apiVersion: argoproj.io/v1alpha1
    kind: AppProject
    metadata:
      name: default
      namespace: {{ $.Release.Namespace | quote }}
      annotations:
        source: gitops-brige
    spec:
      clusterResourceWhitelist:
      - group: '*'
        kind: '*'
      sourceRepos:
        - '*'
      destinations:
        - namespace: '*'
          name: '*'
          server: '*'
